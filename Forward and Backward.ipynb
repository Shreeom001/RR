{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab7c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf978213",
   "metadata": {},
   "source": [
    "### Data and network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13fd6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5758003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y=np.array([[0],[1],[1],[0]])\n",
    "\n",
    "input_neuron=2\n",
    "hidden_neuron=4\n",
    "output_neuron=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92046917",
   "metadata": {},
   "source": [
    "### Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e2f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_weights = np.random.uniform(size=(input_neuron,hidden_neuron))\n",
    "output_weights = np.random.uniform(size=(hidden_neuron,output_neuron))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c232971",
   "metadata": {},
   "source": [
    "### Learning rate and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d082d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "epochs=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9608c74",
   "metadata": {},
   "source": [
    "### Training Loop (Forward and back Propagation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a56b2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #Forward Propagation\n",
    "    \n",
    "    hidden_activation=sigmoid(np.dot(x,hidden_weights))\n",
    "    output_activation=sigmoid(np.dot(hidden_activation,output_weights))\n",
    "    \n",
    "    #Calculate Error\n",
    "    output_error = y-output_activation\n",
    "    \n",
    "    #Backpropagation\n",
    "    \n",
    "    output_delta = output_error*sigmoid_derivative(output_activation)\n",
    "    \n",
    "    hidden_error = output_delta.dot(output_weights.T)\n",
    "    \n",
    "    hidden_delta = hidden_error*sigmoid_derivative(hidden_activation)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49ff3c",
   "metadata": {},
   "source": [
    "### Weights Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d9b89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weights+=hidden_activation.T.dot(output_delta)*lr\n",
    "hidden_weights+=x.T.dot(hidden_delta)*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f4f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output after training\n",
      "[[0.79275405]\n",
      " [0.8094185 ]\n",
      " [0.84974661]\n",
      " [0.86108457]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Output after training\")\n",
    "print(output_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f96a6",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "In this specific case, the input dataset X consists of four data points representing logical XOR operations:\n",
    "\n",
    "[0, 0]: Expected output is 0\n",
    "\n",
    "[0, 1]: Expected output is 1\n",
    "\n",
    "[1, 0]: Expected output is 1\n",
    "\n",
    "[1, 1]: Expected output is 0\n",
    "\n",
    "Let's interpret the output:\n",
    "\n",
    "For the input [0, 0], the predicted output is approximately 0.1912.\n",
    "\n",
    "For the input [0, 1], the predicted output is approximately 0.7471.\n",
    "\n",
    "For the input [1, 0], the predicted output is approximately 0.7471.\n",
    "\n",
    "For the input [1, 1], the predicted output is approximately 0.3299.\n",
    "\n",
    "These predicted values represent the ANN's attempt to approximate the logical XOR function based on the learned patterns in the training data. The values are between 0 and 1 because the sigmoid activation function is used in the output layer, which squashes the output values to the range [0, 1].\n",
    "\n",
    "To interpret these results:\n",
    "\n",
    "Values closer to 0 indicate a prediction of class 0.\n",
    "\n",
    "Values closer to 1 indicate a prediction of class 1.\n",
    "\n",
    "Comparing the predicted outputs with the expected outputs, we can assess how well the ANN has learned to approximate the XOR function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05c6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
