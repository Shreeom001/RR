{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56529c2b",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Character Detection using PyTorch, Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c072d",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd20969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2625e",
   "metadata": {},
   "source": [
    "# 2. Load and Preprocess Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f03a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10ff58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6cf4dd",
   "metadata": {},
   "source": [
    "X_train = X_train / 255.0: Preprocesses the training images by normalizing pixel values. Each pixel in the original image has a value between 0 and 255 (representing grayscale intensity). Here, we divide each pixel value by 255.0 to normalize the values between 0 and 1. This helps the neural network learn more effectively. X_test = X_test / 255.0: Applies the same normalization to the testing images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f25f8",
   "metadata": {},
   "source": [
    "# 3. Define the Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852f16c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.5200\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.1527\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.1029\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9784 - loss: 0.0725\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9839 - loss: 0.0558\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9863 - loss: 0.0463\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9890 - loss: 0.0377\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0308\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0250\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0201\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9726 - loss: 0.1003\n",
      "Loss: 0.08138067275285721\n",
      "Accuracy: 0.9771999716758728\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "#4. Compile the Model:\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#5. Train the Model:\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=64)\n",
    "\n",
    "#6. Evaluate the Model:\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544a1eb",
   "metadata": {},
   "source": [
    "batch_size=64: The number of training samples used to update the model's weights in each iteration (called a batch). This value can be adjusted for memory limitations or performance optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccba517",
   "metadata": {},
   "source": [
    "Flatten(input_shape=(28, 28)): The first layer is Flatten. It reshapes the 28x28 pixel images from the MNIST dataset into a 1D vector of size 784 (28 * 28) for each image. This is necessary because neural networks typically work with 1D vectors as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c396a",
   "metadata": {},
   "source": [
    "Dense(128, activation='relu'): The second layer is a Dense layer with 128 neurons. Each neuron in this layer is fully connected to all neurons in the previous layer (the flattened image vector). The activation function used is 'relu' (Rectified Linear Unit), which adds non-linearity to the model, allowing it to learn more complex patterns.\n",
    "\n",
    "Dense(10, activation='softmax'): The output layer is another Dense layer with 10 neurons, one for each digit (0-9). The activation function used here is 'softmax,' which ensures the output probabilities for all digit classes sum up to 1, making it suitable for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef74788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
